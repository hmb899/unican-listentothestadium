window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "src", "modulename": "src", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.constants", "modulename": "src.constants", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.constants.VERBOSE", "modulename": "src.constants", "qualname": "VERBOSE", "kind": "variable", "doc": "<p></p>\n", "default_value": "True"}, {"fullname": "src.constants.PROJECT_ROOT", "modulename": "src.constants", "qualname": "PROJECT_ROOT", "kind": "variable", "doc": "<p></p>\n", "default_value": "WindowsPath(&#x27;D:/unican-listentothestadium&#x27;)"}, {"fullname": "src.constants.DATA_PREPARATION_PATH", "modulename": "src.constants", "qualname": "DATA_PREPARATION_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "WindowsPath(&#x27;D:/unican-listentothestadium/src/data_preparation&#x27;)"}, {"fullname": "src.constants.GOAL_DETECTION_PATH", "modulename": "src.constants", "qualname": "GOAL_DETECTION_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "WindowsPath(&#x27;D:/unican-listentothestadium/src/goal_detection&#x27;)"}, {"fullname": "src.constants.GOALS_CLASSIFICATION_PATH", "modulename": "src.constants", "qualname": "GOALS_CLASSIFICATION_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "WindowsPath(&#x27;D:/unican-listentothestadium/src/goals_classification&#x27;)"}, {"fullname": "src.constants.TRAINING_PATH", "modulename": "src.constants", "qualname": "TRAINING_PATH", "kind": "variable", "doc": "<p></p>\n", "default_value": "WindowsPath(&#x27;D:/unican-listentothestadium/src/training&#x27;)"}, {"fullname": "src.constants.DATA_DIR", "modulename": "src.constants", "qualname": "DATA_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data&#x27;"}, {"fullname": "src.constants.PRINCIPAL_TEAM", "modulename": "src.constants", "qualname": "PRINCIPAL_TEAM", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Real Madrid&#x27;"}, {"fullname": "src.constants.MATCHES_DIRS", "modulename": "src.constants", "qualname": "MATCHES_DIRS", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables&#x27;"}, {"fullname": "src.constants.PROCESSED_DIR", "modulename": "src.constants", "qualname": "PROCESSED_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Processed&#x27;"}, {"fullname": "src.constants.MODELS_DIR", "modulename": "src.constants", "qualname": "MODELS_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models&#x27;"}, {"fullname": "src.constants.MATCH_NUMBER", "modulename": "src.constants", "qualname": "MATCH_NUMBER", "kind": "variable", "doc": "<p></p>\n", "default_value": "42"}, {"fullname": "src.constants.MATCH_KEY", "modulename": "src.constants", "qualname": "MATCH_KEY", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;RMA-RAYII&#x27;"}, {"fullname": "src.constants.MATCH_DIR", "modulename": "src.constants", "qualname": "MATCH_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII&#x27;"}, {"fullname": "src.constants.JSON_FILE", "modulename": "src.constants", "qualname": "JSON_FILE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII_all_events.json&#x27;"}, {"fullname": "src.constants.EVENTS_FILE", "modulename": "src.constants", "qualname": "EVENTS_FILE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII_all_events_ordered.csv&#x27;"}, {"fullname": "src.constants.VIDEO_FILE", "modulename": "src.constants", "qualname": "VIDEO_FILE", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII.mp4&#x27;"}, {"fullname": "src.constants.RAW_WAV", "modulename": "src.constants", "qualname": "RAW_WAV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII.wav&#x27;"}, {"fullname": "src.constants.TEMP_WAV", "modulename": "src.constants", "qualname": "TEMP_WAV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII_temp.wav&#x27;"}, {"fullname": "src.constants.CLEAN_WAV", "modulename": "src.constants", "qualname": "CLEAN_WAV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII_clean.wav&#x27;"}, {"fullname": "src.constants.NO_VOCALS_WAVS", "modulename": "src.constants", "qualname": "NO_VOCALS_WAVS", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;separated&#x27;"}, {"fullname": "src.constants.WAVELENGTHS_CSV", "modulename": "src.constants", "qualname": "WAVELENGTHS_CSV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII_wavelengths.csv&#x27;"}, {"fullname": "src.constants.EVALUATION_CSV", "modulename": "src.constants", "qualname": "EVALUATION_CSV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Processed\\\\goals_evaluation.csv&#x27;"}, {"fullname": "src.constants.EVENTS_CSV", "modulename": "src.constants", "qualname": "EVENTS_CSV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\RMA-RAYII_all_events_ordered.csv&#x27;"}, {"fullname": "src.constants.FEATURES_CSV", "modulename": "src.constants", "qualname": "FEATURES_CSV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Processed\\\\features.csv&#x27;"}, {"fullname": "src.constants.FINAL_CSV", "modulename": "src.constants", "qualname": "FINAL_CSV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Processed\\\\goals_final.csv&#x27;"}, {"fullname": "src.constants.RESULTS_CSV", "modulename": "src.constants", "qualname": "RESULTS_CSV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Processed\\\\models_results.csv&#x27;"}, {"fullname": "src.constants.FEATURES_TEMP_CSV", "modulename": "src.constants", "qualname": "FEATURES_TEMP_CSV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Processed\\\\goals_features_temp.csv&#x27;"}, {"fullname": "src.constants.GRAPHS_DIR", "modulename": "src.constants", "qualname": "GRAPHS_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\Graphs&#x27;"}, {"fullname": "src.constants.AUDIO_GOALS_DIR", "modulename": "src.constants", "qualname": "AUDIO_GOALS_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Data/Audio_goals/goal&#x27;"}, {"fullname": "src.constants.AUDIO_NO_GOALS_DIR", "modulename": "src.constants", "qualname": "AUDIO_NO_GOALS_DIR", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Data/Audio_goals/no_goal&#x27;"}, {"fullname": "src.constants.GOAL_MODEL_AB", "modulename": "src.constants", "qualname": "GOAL_MODEL_AB", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\goal_ada_boost.pkl&#x27;"}, {"fullname": "src.constants.TEAM_MODEL_AB", "modulename": "src.constants", "qualname": "TEAM_MODEL_AB", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\team_ada_boost.pkl&#x27;"}, {"fullname": "src.constants.GOAL_MODEL_RF", "modulename": "src.constants", "qualname": "GOAL_MODEL_RF", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\goal_rand_forest.pkl&#x27;"}, {"fullname": "src.constants.TEAM_MODEL_RF", "modulename": "src.constants", "qualname": "TEAM_MODEL_RF", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\team_rand_forest.pkl&#x27;"}, {"fullname": "src.constants.GOAL_MODEL_GB", "modulename": "src.constants", "qualname": "GOAL_MODEL_GB", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\goal_gradient.pkl&#x27;"}, {"fullname": "src.constants.TEAM_MODEL_GB", "modulename": "src.constants", "qualname": "TEAM_MODEL_GB", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\team_gradient.pkl&#x27;"}, {"fullname": "src.constants.GOAL_MODEL_CNN", "modulename": "src.constants", "qualname": "GOAL_MODEL_CNN", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\goal_cnn.keras&#x27;"}, {"fullname": "src.constants.GOAL_MODEL_CNN_RAW", "modulename": "src.constants", "qualname": "GOAL_MODEL_CNN_RAW", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\goal_cnn_RAW.keras&#x27;"}, {"fullname": "src.constants.GOAL_MODEL_LSTM", "modulename": "src.constants", "qualname": "GOAL_MODEL_LSTM", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Models\\\\goal_lstm.keras&#x27;"}, {"fullname": "src.constants.AUDIO_PATH_GOL", "modulename": "src.constants", "qualname": "AUDIO_PATH_GOL", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Data/Audio_goals/goal&#x27;"}, {"fullname": "src.constants.AUDIO_PATH_NO_GOL", "modulename": "src.constants", "qualname": "AUDIO_PATH_NO_GOL", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Data/Audio_goals/no_goal&#x27;"}, {"fullname": "src.constants.AB_DETECTED_GOALS", "modulename": "src.constants", "qualname": "AB_DETECTED_GOALS", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\Graphs\\\\ada_boost_goals_madrid_vs_visitor.png&#x27;"}, {"fullname": "src.constants.RAW_DETECTED_GOALS", "modulename": "src.constants", "qualname": "RAW_DETECTED_GOALS", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;D:\\\\unican-listentothestadium\\\\Data\\\\Match_tables\\\\Match_RMA-RAYII\\\\Graphs\\\\raw_goals_detected.png&#x27;"}, {"fullname": "src.data_preparation", "modulename": "src.data_preparation", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_preparation.Json_Data", "modulename": "src.data_preparation.Json_Data", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_preparation.Json_Data.DEBUG", "modulename": "src.data_preparation.Json_Data", "qualname": "DEBUG", "kind": "variable", "doc": "<p>Module for processing JSON event data into a structured CSV format with custom descriptions.</p>\n", "default_value": "False"}, {"fullname": "src.data_preparation.Json_Data.get_nested_value", "modulename": "src.data_preparation.Json_Data", "qualname": "get_nested_value", "kind": "function", "doc": "<p>Safely access nested keys in a dictionary.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>d (dict):</strong>  The dictionary to traverse.</li>\n<li><strong>*keys (str):</strong>  Sequence of keys representing the nested path.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>The value found at the nested path, or None if any key is missing or the object is not a dict.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">d</span>, </span><span class=\"param\"><span class=\"o\">*</span><span class=\"n\">keys</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_pass", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_pass", "kind": "function", "doc": "<p>Extract the pass height name from an event row.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: The name of the pass height, or None if unavailable.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_ball_receipt", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_ball_receipt", "kind": "function", "doc": "<p>Determine if a ball receipt event was incomplete.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: 'incomplete' if the outcome was 'Incomplete', otherwise None.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_carry", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_carry", "kind": "function", "doc": "<p>Check if a carry event occurred under pressure.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: 'under pressure' if under_pressure flag is True, otherwise None.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_simple_outcome", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_simple_outcome", "kind": "function", "doc": "<p>Extract a simple outcome name for events like dribble, duel, shot, etc.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n<li><strong>field (str):</strong>  The event field to inspect (e.g., 'dribble', 'duel').</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: The outcome name, or None if unavailable.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span>, </span><span class=\"param\"><span class=\"n\">field</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_clearance", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_clearance", "kind": "function", "doc": "<p>Extract the body part used for a clearance event.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: The body part name, or None if unavailable.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_goalkeeper", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_goalkeeper", "kind": "function", "doc": "<p>Extract the goalkeeper action type name.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: The goalkeeper action type name, or None if unavailable.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_substitution", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_substitution", "kind": "function", "doc": "<p>Extract the replacement player name for substitution events.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: The replacement player's name, or None if unavailable.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.handle_ball_recovery", "modulename": "src.data_preparation.Json_Data", "qualname": "handle_ball_recovery", "kind": "function", "doc": "<p>Determine if a ball recovery event failed.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: 'failure' if recovery_failure flag is True, otherwise None.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.get_description", "modulename": "src.data_preparation.Json_Data", "qualname": "get_description", "kind": "function", "doc": "<p>Generate a custom description for an event based on its type.</p>\n\n<p>This function maps event types to their corresponding handler functions.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pandas.Series):</strong>  A row from the events DataFrame.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str or None: A description string or None if no handler exists for the event type.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.Json_Data.main", "modulename": "src.data_preparation.Json_Data", "qualname": "main", "kind": "function", "doc": "<p>Main execution function to read JSON events, transform them, and write to CSV.</p>\n\n<h6 id=\"steps\">Steps:</h6>\n\n<blockquote>\n  <ol>\n  <li>Load JSON data from file.</li>\n  <li>Compute period, start, and end timestamps.</li>\n  <li>Adjust second-half timings.</li>\n  <li>Extract team, player, location, and type fields.</li>\n  <li>Generate custom descriptions.</li>\n  <li>Convert types and write the resulting DataFrame to CSV.</li>\n  </ol>\n</blockquote>\n\n<h6 id=\"raises\">Raises:</h6>\n\n<ul>\n<li><strong>FileNotFoundError:</strong>  If the JSON_FILE cannot be found or opened.</li>\n<li><strong>ValueError:</strong>  If data types conversion fails.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis", "modulename": "src.data_preparation.audio_analysis", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_preparation.audio_analysis.DEBUG", "modulename": "src.data_preparation.audio_analysis", "qualname": "DEBUG", "kind": "variable", "doc": "<p></p>\n", "default_value": "False"}, {"fullname": "src.data_preparation.audio_analysis.BEF", "modulename": "src.data_preparation.audio_analysis", "qualname": "BEF", "kind": "variable", "doc": "<p></p>\n", "default_value": "210"}, {"fullname": "src.data_preparation.audio_analysis.AF", "modulename": "src.data_preparation.audio_analysis", "qualname": "AF", "kind": "variable", "doc": "<p></p>\n", "default_value": "210"}, {"fullname": "src.data_preparation.audio_analysis.CHANT_COLORS", "modulename": "src.data_preparation.audio_analysis", "qualname": "CHANT_COLORS", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;Team A&#x27;: &#x27;green&#x27;, &#x27;Team B&#x27;: &#x27;red&#x27;}"}, {"fullname": "src.data_preparation.audio_analysis.LOC", "modulename": "src.data_preparation.audio_analysis", "qualname": "LOC", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;upper right&#x27;"}, {"fullname": "src.data_preparation.audio_analysis.compute_fft", "modulename": "src.data_preparation.audio_analysis", "qualname": "compute_fft", "kind": "function", "doc": "<p>Compute the FFT and decibel values for a given audio segment.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>segment (np.ndarray):</strong>  Audio data segment.</li>\n<li><strong>sample_rate (int):</strong>  Sampling rate in Hz.</li>\n<li><strong>apply_window (bool):</strong>  Whether to apply a Hanning window.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple: Frequencies (Hz) and corresponding decibel values.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">segment</span>, </span><span class=\"param\"><span class=\"n\">sample_rate</span>, </span><span class=\"param\"><span class=\"n\">apply_window</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.get_audio_duration", "modulename": "src.data_preparation.audio_analysis", "qualname": "get_audio_duration", "kind": "function", "doc": "<p>Get the duration (in seconds) of an audio file.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>audio_path (str):</strong>  Path to the audio file.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>float: Duration of the audio file in seconds.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">audio_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.compute_average_decibels", "modulename": "src.data_preparation.audio_analysis", "qualname": "compute_average_decibels", "kind": "function", "doc": "<p>Compute average decibel spectrum across a list of time intervals.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>intervals (list):</strong>  List of (start, end) time intervals in seconds.</li>\n<li><strong>samples (np.ndarray):</strong>  Audio samples.</li>\n<li><strong>sample_rate (int):</strong>  Sampling rate in Hz.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple: Frequency bins and average decibel values, or (None, None) if invalid.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">sample_rate</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.extract_audio_segment", "modulename": "src.data_preparation.audio_analysis", "qualname": "extract_audio_segment", "kind": "function", "doc": "<p>Extract an audio segment from sample data given start and end times.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>samples (np.ndarray):</strong>  Audio samples.</li>\n<li><strong>start (float):</strong>  Start time in seconds.</li>\n<li><strong>end (float):</strong>  End time in seconds.</li>\n<li><strong>sample_rate (int):</strong>  Sampling rate in Hz.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray or None: Extracted audio segment or None if invalid.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">start</span>, </span><span class=\"param\"><span class=\"n\">end</span>, </span><span class=\"param\"><span class=\"n\">sample_rate</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.find_resonance_frequency", "modulename": "src.data_preparation.audio_analysis", "qualname": "find_resonance_frequency", "kind": "function", "doc": "<p>Identify the median of the three consecutive frequencies with highest energy.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>frequency_bins (np.ndarray):</strong>  Frequency values.</li>\n<li><strong>decibel_avg (np.ndarray):</strong>  Corresponding average decibel values.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>float: Resonance frequency in Hz.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">frequency_bins</span>, </span><span class=\"param\"><span class=\"n\">decibel_avg</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.get_intervals_from_dataframe", "modulename": "src.data_preparation.audio_analysis", "qualname": "get_intervals_from_dataframe", "kind": "function", "doc": "<p>Extract time intervals for events from a DataFrame.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>events_df (pd.DataFrame):</strong>  DataFrame with event metadata.</li>\n<li><strong>duration (float):</strong>  Total audio duration to clip interval ends.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>dict: Dictionary mapping team names to lists of (start, end) tuples.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">events_df</span>, </span><span class=\"param\"><span class=\"n\">duration</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.extract_audio_segments", "modulename": "src.data_preparation.audio_analysis", "qualname": "extract_audio_segments", "kind": "function", "doc": "<p>Save audio segments to WAV files based on event intervals.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>match_audio (str):</strong>  Path to the match audio file.</li>\n<li><strong>intervals (dict):</strong>  Dictionary of intervals per team.</li>\n<li><strong>output_dirs (dict):</strong>  Output directories per team for saving WAV segments.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">match_audio</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">output_dirs</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.analyze_audio_events", "modulename": "src.data_preparation.audio_analysis", "qualname": "analyze_audio_events", "kind": "function", "doc": "<p>Analyze audio events to compute average dB and resonance frequency per event.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>match_audio (str):</strong>  Path to the match audio file.</li>\n<li><strong>intervals (dict):</strong>  Dictionary of intervals per team.</li>\n<li><strong>output_csv (str):</strong>  Path to CSV file for storing analysis results.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">match_audio</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">output_csv</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.plot_audio_db_with_events", "modulename": "src.data_preparation.audio_analysis", "qualname": "plot_audio_db_with_events", "kind": "function", "doc": "<p>Plot the dB energy over time with annotated event intervals.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>match_audio (str):</strong>  Path to the match audio file.</li>\n<li><strong>intervals (dict):</strong>  Dictionary of event intervals.</li>\n<li><strong>audio_plot (str):</strong>  Output path for saving the plot.</li>\n<li><strong>event_type (str):</strong>  Label for the type of event (e.g. 'Goals').</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">match_audio</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">audio_plot</span>, </span><span class=\"param\"><span class=\"n\">event_type</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.plot_freq_events", "modulename": "src.data_preparation.audio_analysis", "qualname": "plot_freq_events", "kind": "function", "doc": "<p>Plot frequency vs average dB for each team's events.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>match_audio (str):</strong>  Path to the match audio file.</li>\n<li><strong>intervals (dict):</strong>  Dictionary of event intervals.</li>\n<li><strong>spectrum_plot (str):</strong>  Path for the output plot.</li>\n<li><strong>event_type (str):</strong>  Type of event (e.g. 'Goals').</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">match_audio</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">spectrum_plot</span>, </span><span class=\"param\"><span class=\"n\">event_type</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.save_frequency_plot", "modulename": "src.data_preparation.audio_analysis", "qualname": "save_frequency_plot", "kind": "function", "doc": "<p>Save a frequency-decibel plot with resonance frequency marked.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>frequency_bins (np.ndarray):</strong>  Frequency values in Hz.</li>\n<li><strong>decibel_avg (np.ndarray):</strong>  Average dB levels.</li>\n<li><strong>team (str):</strong>  Team label.</li>\n<li><strong>resonance_frequency (float):</strong>  Detected resonance frequency.</li>\n<li><strong>spectrum_plot (str):</strong>  Output path for saving plot.</li>\n<li><strong>event_type (str):</strong>  Type of event for title/label.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">frequency_bins</span>,</span><span class=\"param\">\t<span class=\"n\">decibel_avg</span>,</span><span class=\"param\">\t<span class=\"n\">team</span>,</span><span class=\"param\">\t<span class=\"n\">resonance_frequency</span>,</span><span class=\"param\">\t<span class=\"n\">spectrum_plot</span>,</span><span class=\"param\">\t<span class=\"n\">event_type</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_analysis.main", "modulename": "src.data_preparation.audio_analysis", "qualname": "main", "kind": "function", "doc": "<p>Main function to execute the audio analysis pipeline:</p>\n\n<ul>\n<li>Load audio and event metadata</li>\n<li>Filter goal events</li>\n<li>Plot waveforms, energy, frequency</li>\n<li>Optionally export detailed audio metrics (if DEBUG=True)</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner", "modulename": "src.data_preparation.audio_cleaner", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_preparation.audio_cleaner.DEBUG", "modulename": "src.data_preparation.audio_cleaner", "qualname": "DEBUG", "kind": "variable", "doc": "<p>Audio processing pipeline:</p>\n\n<ol>\n<li>Remove commentator voice using source separation (Demucs).</li>\n<li>Apply FIR low-pass filter to remove high frequencies.</li>\n<li>Normalize and clip audio around goal event intervals.</li>\n<li>Evaluate amplitude metrics for goal events.</li>\n</ol>\n", "default_value": "True"}, {"fullname": "src.data_preparation.audio_cleaner.remove_commentator", "modulename": "src.data_preparation.audio_cleaner", "qualname": "remove_commentator", "kind": "function", "doc": "<p>Extract audio from a video file and remove vocal tracks using Demucs.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>input_video (str):</strong>  Path to the input video file.</li>\n<li><strong>output_audio (str):</strong>  Path where the processed audio (no vocals) will be saved.</li>\n</ul>\n\n<h6 id=\"raises\">Raises:</h6>\n\n<ul>\n<li><strong>subprocess.CalledProcessError:</strong>  If ffmpeg or demucs commands fail.</li>\n<li><strong>FileNotFoundError:</strong>  If temporary audio or separation output directories are missing.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_video</span>, </span><span class=\"param\"><span class=\"n\">output_audio</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.fir_lowpass", "modulename": "src.data_preparation.audio_cleaner", "qualname": "fir_lowpass", "kind": "function", "doc": "<p>Design a low-pass FIR filter using a Hamming window.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>cutoff (float):</strong>  Cutoff frequency in Hz.</li>\n<li><strong>transition_width (float):</strong>  Transition band width in Hz.</li>\n<li><strong>fs (int):</strong>  Sampling frequency of the signal in Hz.</li>\n<li><strong>numtaps (int):</strong>  Number of filter coefficients (taps).</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: FIR filter coefficients.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cutoff</span>, </span><span class=\"param\"><span class=\"n\">transition_width</span>, </span><span class=\"param\"><span class=\"n\">fs</span>, </span><span class=\"param\"><span class=\"n\">numtaps</span><span class=\"o\">=</span><span class=\"mi\">512</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.apply_fir_filter", "modulename": "src.data_preparation.audio_cleaner", "qualname": "apply_fir_filter", "kind": "function", "doc": "<p>Apply an FIR filter to a 1D audio array.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>data (np.ndarray):</strong>  Input audio samples.</li>\n<li><strong>fir_coeff (np.ndarray):</strong>  FIR filter coefficients.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Filtered audio samples.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">data</span>, </span><span class=\"param\"><span class=\"n\">fir_coeff</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.filter_audio", "modulename": "src.data_preparation.audio_cleaner", "qualname": "filter_audio", "kind": "function", "doc": "<p>Read a WAV file, apply a low-pass FIR filter, amplify, and save result.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>input_wav (str):</strong>  Path to the input WAV file.</li>\n<li><strong>output_wav (str):</strong>  Path to the filtered output WAV file.</li>\n<li><strong>cutoff (float):</strong>  Cutoff frequency in Hz for low-pass filter.</li>\n<li><strong>transition (float):</strong>  Transition width in Hz.</li>\n<li><strong>gain (float):</strong>  Gain factor to apply after filtering.</li>\n</ul>\n\n<h6 id=\"raises\">Raises:</h6>\n\n<ul>\n<li><strong>ValueError:</strong>  If WAV file cannot be read or has unsupported format.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_wav</span>, </span><span class=\"param\"><span class=\"n\">output_wav</span>, </span><span class=\"param\"><span class=\"n\">cutoff</span>, </span><span class=\"param\"><span class=\"n\">transition</span>, </span><span class=\"param\"><span class=\"n\">gain</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.normalize_audio", "modulename": "src.data_preparation.audio_cleaner", "qualname": "normalize_audio", "kind": "function", "doc": "<p>Normalize audio samples to a target peak level.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>samples (np.ndarray):</strong>  Input audio samples.</li>\n<li><strong>target_level (float):</strong>  Desired maximum absolute amplitude.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Normalized audio samples.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">target_level</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.soft_clip", "modulename": "src.data_preparation.audio_cleaner", "qualname": "soft_clip", "kind": "function", "doc": "<p>Apply soft clipping using a tanh-based limiter.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>samples (np.ndarray):</strong>  Input audio samples.</li>\n<li><strong>threshold (float):</strong>  Clipping threshold as a fraction of peak.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Soft-clipped audio samples.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">threshold</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.save_modified_audio", "modulename": "src.data_preparation.audio_cleaner", "qualname": "save_modified_audio", "kind": "function", "doc": "<p>Save numpy audio samples as a WAV file via pydub.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>samples (np.ndarray):</strong>  Audio samples (int16 range).</li>\n<li><strong>sample_rate (int):</strong>  Sampling rate in Hz.</li>\n<li><strong>output_path (str):</strong>  Path to save the WAV file.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">sample_rate</span>, </span><span class=\"param\"><span class=\"n\">output_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.get_intervals_from_events", "modulename": "src.data_preparation.audio_cleaner", "qualname": "get_intervals_from_events", "kind": "function", "doc": "<p>Extract event intervals (start, end+20s) grouped by team.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>events_df (pd.DataFrame):</strong>  DataFrame containing 'Team', 'Start', 'End'.</li>\n<li><strong>duration (float):</strong>  Total duration of the audio in seconds.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>dict[str, list[tuple[int, int]]]: Mapping from team name to list of intervals.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">events_df</span>, </span><span class=\"param\"><span class=\"n\">duration</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.amplify_intervals", "modulename": "src.data_preparation.audio_cleaner", "qualname": "amplify_intervals", "kind": "function", "doc": "<p>Amplify audio samples differently inside specified intervals.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>samples (np.ndarray):</strong>  Original audio samples.</li>\n<li><strong>sample_rate (int):</strong>  Sampling rate in Hz.</li>\n<li><strong>intervals (dict):</strong>  Team-wise intervals to amplify more.</li>\n<li><strong>factor_interval (float):</strong>  Gain factor for interval segments.</li>\n<li><strong>factor_rest (float):</strong>  Gain factor for rest of audio.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Amplified audio samples clipped to int16 range.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">sample_rate</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">factor_interval</span><span class=\"o\">=</span><span class=\"mf\">4.0</span>, </span><span class=\"param\"><span class=\"n\">factor_rest</span><span class=\"o\">=</span><span class=\"mi\">2</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.save_amplitudes_per_second", "modulename": "src.data_preparation.audio_cleaner", "qualname": "save_amplitudes_per_second", "kind": "function", "doc": "<p>Compute smoothed amplitude envelope per second and save to CSV.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>audio_file (str):</strong>  Path to input WAV file.</li>\n<li><strong>output_csv (str):</strong>  Path for output CSV with 'second' and 'amplitude'.</li>\n<li><strong>frame_duration (float):</strong>  Duration of each analysis frame (s).</li>\n<li><strong>hop_duration (float):</strong>  Hop length between frames (s).</li>\n<li><strong>smoothing_window_duration (float):</strong>  Window for smoothing (s).</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audio_file</span>,</span><span class=\"param\">\t<span class=\"n\">output_csv</span>,</span><span class=\"param\">\t<span class=\"n\">frame_duration</span><span class=\"o\">=</span><span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">hop_duration</span><span class=\"o\">=</span><span class=\"mf\">0.05</span>,</span><span class=\"param\">\t<span class=\"n\">smoothing_window_duration</span><span class=\"o\">=</span><span class=\"mf\">0.5</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.evaluate_goals", "modulename": "src.data_preparation.audio_cleaner", "qualname": "evaluate_goals", "kind": "function", "doc": "<p>Analyze amplitude CSV and record metrics for goal intervals.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>amplitudes_csv (str):</strong>  CSV with 'second' and 'amplitude'.</li>\n<li><strong>evaluation_csv (str):</strong>  Path to store or update evaluation CSV.</li>\n<li><strong>goals_intervals (dict):</strong>  Mapping from team to goal intervals.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">amplitudes_csv</span>, </span><span class=\"param\"><span class=\"n\">evaluation_csv</span>, </span><span class=\"param\"><span class=\"n\">goals_intervals</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.normalize_and_clip_audio", "modulename": "src.data_preparation.audio_cleaner", "qualname": "normalize_and_clip_audio", "kind": "function", "doc": "<p>Normalize and apply soft clipping to audio based on goal events.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>wav_path (str):</strong>  Path to input WAV file.</li>\n<li><strong>output_wav (str):</strong>  Path to save processed WAV file.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">wav_path</span>, </span><span class=\"param\"><span class=\"n\">output_wav</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.audio_cleaner.main", "modulename": "src.data_preparation.audio_cleaner", "qualname": "main", "kind": "function", "doc": "<p>Execute the full audio cleaning pipeline from video to final WAV.</p>\n\n<h6 id=\"raises\">Raises:</h6>\n\n<ul>\n<li><strong>OSError:</strong>  If file operations (remove/commentator) fail.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.search_goals", "modulename": "src.data_preparation.search_goals", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_preparation.search_goals.DEBUG", "modulename": "src.data_preparation.search_goals", "qualname": "DEBUG", "kind": "variable", "doc": "<p></p>\n", "default_value": "False"}, {"fullname": "src.data_preparation.search_goals.GOAL_TIME", "modulename": "src.data_preparation.search_goals", "qualname": "GOAL_TIME", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;Goal_Start_Time[S]&#x27;"}, {"fullname": "src.data_preparation.search_goals.detect_intervals", "modulename": "src.data_preparation.search_goals", "qualname": "detect_intervals", "kind": "function", "doc": "<p>Detects high-energy intervals in an audio file based on envelope smoothing.</p>\n\n<p>Args:\n     audio_file (str): Path to the audio file.\n     low_threshold (float): Minimum amplitude to start checking for a high-energy segment.\n     high_threshold (float): Threshold that the average amplitude of a high-energy segment must exceed.\n     min_high_duration (float): Minimum duration in seconds of a high-energy segment.\n     frame_duration (float): Duration in seconds for each analysis frame.\n     hop_duration (float): Duration in seconds between frames.\n     smoothing_window_duration (float): Duration of the smoothing window in seconds.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>list[tuple[float, float]]: List of tuples representing the start and end times (in seconds)\n      of detected high-energy intervals.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audio_file</span>,</span><span class=\"param\">\t<span class=\"n\">low_threshold</span><span class=\"o\">=</span><span class=\"mf\">0.3</span>,</span><span class=\"param\">\t<span class=\"n\">high_threshold</span><span class=\"o\">=</span><span class=\"mf\">0.3</span>,</span><span class=\"param\">\t<span class=\"n\">min_high_duration</span><span class=\"o\">=</span><span class=\"mf\">12.0</span>,</span><span class=\"param\">\t<span class=\"n\">frame_duration</span><span class=\"o\">=</span><span class=\"mf\">0.1</span>,</span><span class=\"param\">\t<span class=\"n\">hop_duration</span><span class=\"o\">=</span><span class=\"mf\">0.05</span>,</span><span class=\"param\">\t<span class=\"n\">smoothing_window_duration</span><span class=\"o\">=</span><span class=\"mf\">0.5</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.search_goals.extract_interval_features", "modulename": "src.data_preparation.search_goals", "qualname": "extract_interval_features", "kind": "function", "doc": "<p>Extracts audio features from a specified interval in the audio signal.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>samples (np.ndarray):</strong>  Audio time series.</li>\n<li><strong>sample_rate (int):</strong>  Sampling rate of the audio.</li>\n<li><strong>start (float):</strong>  Start time in seconds of the interval.</li>\n<li><strong>end (float):</strong>  End time in seconds of the interval.</li>\n<li><strong>window_duration (float):</strong>  Duration in seconds of each frame used for amplitude analysis.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>dict: A dictionary containing extracted features including amplitude (in dB),\n      time points, resonant frequency, average energy, spectral centroid, etc.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">sample_rate</span>, </span><span class=\"param\"><span class=\"n\">start</span>, </span><span class=\"param\"><span class=\"n\">end</span>, </span><span class=\"param\"><span class=\"n\">window_duration</span><span class=\"o\">=</span><span class=\"mf\">0.1</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.search_goals.save_features_table", "modulename": "src.data_preparation.search_goals", "qualname": "save_features_table", "kind": "function", "doc": "<p>Saves or updates a CSV file with extracted features from audio intervals.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>intervals_features (list[dict]):</strong>  List of feature dictionaries for each interval.</li>\n<li><strong>output_path (str):</strong>  Path to the CSV file where data should be saved or updated.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">intervals_features</span>, </span><span class=\"param\"><span class=\"n\">output_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_preparation.search_goals.main", "modulename": "src.data_preparation.search_goals", "qualname": "main", "kind": "function", "doc": "<p>Main execution flow to detect goal events in an audio file and extract features.</p>\n\n<p>Loads an audio file, detects high-energy intervals (e.g., goal events),\nextracts acoustic features for each interval, and saves or updates them in a CSV file.\nIncludes optional visualizations for debugging.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection", "modulename": "src.goal_detection", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.goal_detection.goal_detector_ada_boost", "modulename": "src.goal_detection.goal_detector_ada_boost", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.goal_detection.goal_detector_ada_boost.convert_column", "modulename": "src.goal_detection.goal_detector_ada_boost", "qualname": "convert_column", "kind": "function", "doc": "<p>Converts a column of lists or list-like strings to their mean float values.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>column (pd.Series):</strong>  A pandas Series containing numeric lists or list-like strings.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>pd.Series: A Series with each entry converted to the mean value of the list.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">column</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection.goal_detector_ada_boost.extract_and_save_features", "modulename": "src.goal_detection.goal_detector_ada_boost", "qualname": "extract_and_save_features", "kind": "function", "doc": "<p>Extracts audio features for given intervals and saves them to a CSV file.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>audio_file (str):</strong>  Path to the audio file.</li>\n<li><strong>intervals (list[tuple[float, float]]):</strong>  List of (start, end) time intervals in seconds.</li>\n<li><strong>output_csv (str):</strong>  Path to the output CSV file where features will be saved.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>pd.DataFrame: DataFrame containing the extracted features.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">audio_file</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">output_csv</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection.goal_detector_ada_boost.process_feature_dataframe", "modulename": "src.goal_detection.goal_detector_ada_boost", "qualname": "process_feature_dataframe", "kind": "function", "doc": "<p>Preprocesses the feature DataFrame by removing irrelevant columns and converting list values.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>df (pd.DataFrame):</strong>  DataFrame containing raw extracted features.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>pd.DataFrame: Cleaned and processed feature DataFrame ready for prediction.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection.goal_detector_ada_boost.predict_goals_and_teams", "modulename": "src.goal_detection.goal_detector_ada_boost", "qualname": "predict_goals_and_teams", "kind": "function", "doc": "<p>Predicts goal occurrences and the scoring team from features using trained models.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>df (pd.DataFrame):</strong>  Preprocessed feature DataFrame.</li>\n<li><strong>intervals (list[tuple[float, float]]):</strong>  Original detected time intervals.</li>\n<li><strong>goal_model:</strong>  Trained goal classification model (e.g., AdaBoost).</li>\n<li><strong>team_model:</strong>  Trained team classification model.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple:\n      - list[tuple[float, float]]: Intervals classified as goals.\n      - list[int]: Predicted team labels for the goals (e.g., 1 for home, 0 for visitor).</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">goal_model</span>, </span><span class=\"param\"><span class=\"n\">team_model</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection.goal_detector_ada_boost.display_results", "modulename": "src.goal_detection.goal_detector_ada_boost", "qualname": "display_results", "kind": "function", "doc": "<p>Displays and returns goal intervals with associated team predictions.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>real_goals (list[tuple[float, float]]):</strong>  Intervals classified as goals.</li>\n<li><strong>teams (list[int]):</strong>  Corresponding team predictions.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>dict: Dictionary with team names as keys and lists of their goal intervals as values.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">real_goals</span>, </span><span class=\"param\"><span class=\"n\">teams</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection.goal_detector_ada_boost.main", "modulename": "src.goal_detection.goal_detector_ada_boost", "qualname": "main", "kind": "function", "doc": "<p>Main function to run the AdaBoost-based goal and team prediction pipeline.</p>\n\n<p>Detects goal-like audio intervals, extracts features, predicts actual goals using a model,\nclassifies the team, visualizes the results, and logs output.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection.goal_detector_lstm_model", "modulename": "src.goal_detection.goal_detector_lstm_model", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.goal_detection.goal_detector_lstm_model.SAMPLE_RATE", "modulename": "src.goal_detection.goal_detector_lstm_model", "qualname": "SAMPLE_RATE", "kind": "variable", "doc": "<p></p>\n", "default_value": "22050"}, {"fullname": "src.goal_detection.goal_detector_lstm_model.WINDOW_DURATION", "modulename": "src.goal_detection.goal_detector_lstm_model", "qualname": "WINDOW_DURATION", "kind": "variable", "doc": "<p></p>\n", "default_value": "20"}, {"fullname": "src.goal_detection.goal_detector_lstm_model.WINDOW_SIZE", "modulename": "src.goal_detection.goal_detector_lstm_model", "qualname": "WINDOW_SIZE", "kind": "variable", "doc": "<p></p>\n", "default_value": "441000"}, {"fullname": "src.goal_detection.goal_detector_lstm_model.THRESHOLD", "modulename": "src.goal_detection.goal_detector_lstm_model", "qualname": "THRESHOLD", "kind": "variable", "doc": "<p></p>\n", "default_value": "0.8"}, {"fullname": "src.goal_detection.goal_detector_lstm_model.detect_goal_intervals", "modulename": "src.goal_detection.goal_detector_lstm_model", "qualname": "detect_goal_intervals", "kind": "function", "doc": "<p>Detects goal-like segments in raw audio using a trained CNN model.</p>\n\n<p>The function splits the audio into fixed-size windows, runs predictions on each window,\nand returns the time intervals where a goal is likely detected based on a confidence threshold.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>model (keras.Model):</strong>  Trained CNN model for goal detection.</li>\n<li><strong>audio (np.ndarray):</strong>  Raw audio signal.</li>\n<li><strong>sample_rate (int):</strong>  Sample rate of the audio.</li>\n<li><strong>window_duration (int):</strong>  Duration in seconds of each analysis window.</li>\n<li><strong>threshold (float):</strong>  Confidence threshold to classify a window as a goal.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>list[tuple[float, float]]: List of detected goal intervals as (start_time, end_time) in seconds.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">audio</span>, </span><span class=\"param\"><span class=\"n\">sample_rate</span>, </span><span class=\"param\"><span class=\"n\">window_duration</span>, </span><span class=\"param\"><span class=\"n\">threshold</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goal_detection.goal_detector_lstm_model.main", "modulename": "src.goal_detection.goal_detector_lstm_model", "qualname": "main", "kind": "function", "doc": "<p>Main function to run raw audio goal detection using a CNN.</p>\n\n<p>Loads a pretrained CNN model and audio data, applies the model to detect\npossible goal intervals, and visualizes the results.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goals_classification", "modulename": "src.goals_classification", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.goals_classification.goals_success", "modulename": "src.goals_classification.goals_success", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.goals_classification.goals_success.identify_team", "modulename": "src.goals_classification.goals_success", "qualname": "identify_team", "kind": "function", "doc": "<p>Assigns a team to a detected goal based on its proximity to annotated evaluation data.</p>\n\n<p>Compares the goal's timestamp against annotated goal start times in <code>df_eval</code>.\nIf the time difference is within the threshold, assigns the corresponding team.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>row (pd.Series):</strong>  A row from the features DataFrame containing 'Match_Number' and 'Goal_Start_Time[S]'.</li>\n<li><strong>df_eval (pd.DataFrame):</strong>  Evaluation DataFrame with annotated goals.</li>\n<li><strong>threshold (int, optional):</strong>  Maximum time difference (in seconds) to consider a match. Defaults to 20.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>str: 'Real Madrid' if the team is Real Madrid, 'Visitor' if not, or '' if no match is found.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">row</span>, </span><span class=\"param\"><span class=\"n\">df_eval</span>, </span><span class=\"param\"><span class=\"n\">threshold</span><span class=\"o\">=</span><span class=\"mi\">20</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goals_classification.goals_success.main", "modulename": "src.goals_classification.goals_success", "qualname": "main", "kind": "function", "doc": "<p>Determines the success of detected goals by matching them with evaluation data.</p>\n\n<p>Reads the extracted features and evaluation CSV files, attempts to match each goal\nwith annotated data based on time proximity, and labels the goal as a success or not.</p>\n\n<p>The final DataFrame with success labels and team assignments is saved to FINAL_CSV.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.goals_classification.split_goals", "modulename": "src.goals_classification.split_goals", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.goals_classification.split_goals.SEGMENT_DURATION_SEC", "modulename": "src.goals_classification.split_goals", "qualname": "SEGMENT_DURATION_SEC", "kind": "variable", "doc": "<p></p>\n", "default_value": "20"}, {"fullname": "src.goals_classification.split_goals.main", "modulename": "src.goals_classification.split_goals", "qualname": "main", "kind": "function", "doc": "<p>Extracts 20-second audio segments around goal events and saves them into categorized folders.</p>\n\n<p>This script reads goal metadata from a CSV file, loads the corresponding match audio,\nand saves 20-second segments into separate directories for successful and unsuccessful goals.</p>\n\n<p>Processing is done per match, and each segment is saved with a filename that includes\nthe match number and the row index.</p>\n\n<h6 id=\"folders-are-created-if-they-do-not-exist\">Folders are created if they do not exist:</h6>\n\n<blockquote>\n  <ul>\n  <li>AUDIO_GOALS_DIR: For segments labeled as successful goals.</li>\n  <li>AUDIO_NO_GOALS_DIR: For segments labeled as non-goals or missed predictions.</li>\n  </ul>\n</blockquote>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.match_mapping", "modulename": "src.match_mapping", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.match_mapping.match_mapping", "modulename": "src.match_mapping", "qualname": "match_mapping", "kind": "variable", "doc": "<p></p>\n", "default_value": "{1: &#x27;RMA-SEV&#x27;, 2: &#x27;RMA-LPA&#x27;, 3: &#x27;RMA-ALA&#x27;, 4: &#x27;RMA-BAR&#x27;, 5: &#x27;RMA-GET&#x27;, 6: &#x27;RMA-GIR&#x27;, 7: &#x27;RMA-ATM&#x27;, 8: &#x27;RMA-OSA&#x27;, 9: &#x27;RMA-VIL&#x27;, 10: &#x27;RMA-ESP&#x27;, 11: &#x27;RMA-BET&#x27;, 12: &#x27;RMA-VLL&#x27;, 13: &#x27;RMA-CADI&#x27;, 14: &#x27;RMA-OSAI&#x27;, 15: &#x27;RMA-ALAI&#x27;, 16: &#x27;RMA-BETI&#x27;, 17: &#x27;RMA-GRAI&#x27;, 18: &#x27;RMA-VALI&#x27;, 19: &#x27;RMA-LPAI&#x27;, 20: &#x27;RMA-RSOI&#x27;, 21: &#x27;RMA-GETI&#x27;, 22: &#x27;RMA-BARI&#x27;, 23: &#x27;RMA-ATHI&#x27;, 24: &#x27;RMA-CELI&#x27;, 25: &#x27;RMA-GIRI&#x27;, 26: &#x27;RMA-ATMI&#x27;, 27: &#x27;RMA-ALMI&#x27;, 28: &#x27;RMA-MLLI&#x27;, 29: &#x27;RMA-VILI&#x27;, 30: &#x27;RMA-RAYI&#x27;, 31: &#x27;RMA-ALMII&#x27;, 32: &#x27;RMA-ATHII&#x27;, 33: &#x27;RMA-ATMII&#x27;, 34: &#x27;RMA-BARII&#x27;, 35: &#x27;RMA-CADII&#x27;, 36: &#x27;RMA-CELII&#x27;, 37: &#x27;RMA-ELCII&#x27;, 38: &#x27;RMA-ESPII&#x27;, 39: &#x27;RMA-GETII&#x27;, 40: &#x27;RMA-GIRII&#x27;, 41: &#x27;RMA-OSAII&#x27;, 42: &#x27;RMA-RAYII&#x27;, 43: &#x27;RMA-RSOII&#x27;, 44: &#x27;RMA-SEVII&#x27;, 45: &#x27;RMA-VALII&#x27;, 46: &#x27;RMA-VILII&#x27;, 47: &#x27;RMA-VLLII&#x27;}"}, {"fullname": "src.training", "modulename": "src.training", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.ada_boost", "modulename": "src.training.ada_boost", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.ada_boost.VERBOSE", "modulename": "src.training.ada_boost", "qualname": "VERBOSE", "kind": "variable", "doc": "<p></p>\n", "default_value": "True"}, {"fullname": "src.training.ada_boost.main", "modulename": "src.training.ada_boost", "qualname": "main", "kind": "function", "doc": "<p>Main function to train and evaluate AdaBoost classifiers for goal success and team prediction.</p>\n\n<p>This function performs the following steps:</p>\n\n<ol>\n<li>Loads and preprocesses data from a CSV file.</li>\n<li>Trains an AdaBoost classifier to predict 'Goal_Success'.</li>\n<li>Evaluates the performance of the classifier on validation and test sets.</li>\n<li>Trains a second AdaBoost classifier to predict the 'Team' when a goal is successful.</li>\n<li>Saves the trained models using joblib.</li>\n</ol>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn", "modulename": "src.training.cnn", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.cnn.SAMPLE_RATE", "modulename": "src.training.cnn", "qualname": "SAMPLE_RATE", "kind": "variable", "doc": "<p></p>\n", "default_value": "22050"}, {"fullname": "src.training.cnn.N_MFCC", "modulename": "src.training.cnn", "qualname": "N_MFCC", "kind": "variable", "doc": "<p></p>\n", "default_value": "40"}, {"fullname": "src.training.cnn.MAX_PAD", "modulename": "src.training.cnn", "qualname": "MAX_PAD", "kind": "variable", "doc": "<p></p>\n", "default_value": "100"}, {"fullname": "src.training.cnn.extract_mfcc", "modulename": "src.training.cnn", "qualname": "extract_mfcc", "kind": "function", "doc": "<p>Extract MFCC features from an audio file and return the padded version.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>file_path (str):</strong>  Path to the audio file.</li>\n<li><strong>max_pad (int):</strong>  Maximum number of frames to pad or truncate the MFCC feature.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Transposed MFCC feature matrix, padded or truncated to max_pad frames.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">file_path</span>, </span><span class=\"param\"><span class=\"n\">max_pad</span><span class=\"o\">=</span><span class=\"mi\">100</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn.load_data", "modulename": "src.training.cnn", "qualname": "load_data", "kind": "function", "doc": "<p>Load and preprocess the data, extract MFCC features and assign labels.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Array of MFCC features.\n  np.ndarray: Array of corresponding labels ('gol' or 'no_gol').</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn.build_model", "modulename": "src.training.cnn", "qualname": "build_model", "kind": "function", "doc": "<p>Build and compile a 2D convolutional neural network model.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>input_shape (tuple):</strong>  The shape of the input data.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tf.keras.Model: The compiled CNN model.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_shape</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn.main", "modulename": "src.training.cnn", "qualname": "main", "kind": "function", "doc": "<p>Main function to load data, build and train the model, and evaluate the results.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn_1d", "modulename": "src.training.cnn_1d", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.cnn_1d.SAMPLE_RATE", "modulename": "src.training.cnn_1d", "qualname": "SAMPLE_RATE", "kind": "variable", "doc": "<p></p>\n", "default_value": "22050"}, {"fullname": "src.training.cnn_1d.DURATION", "modulename": "src.training.cnn_1d", "qualname": "DURATION", "kind": "variable", "doc": "<p></p>\n", "default_value": "2"}, {"fullname": "src.training.cnn_1d.SAMPLES_PER_TRACK", "modulename": "src.training.cnn_1d", "qualname": "SAMPLES_PER_TRACK", "kind": "variable", "doc": "<p></p>\n", "default_value": "44100"}, {"fullname": "src.training.cnn_1d.load_raw_audio", "modulename": "src.training.cnn_1d", "qualname": "load_raw_audio", "kind": "function", "doc": "<p>Load an audio file and pad or truncate it to the target length.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>file_path (str):</strong>  Path to the audio file.</li>\n<li><strong>target_len (int):</strong>  Desired length of the audio in samples.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Audio data, either padded or truncated to target_len.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">file_path</span>, </span><span class=\"param\"><span class=\"n\">target_len</span><span class=\"o\">=</span><span class=\"mi\">44100</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn_1d.load_data", "modulename": "src.training.cnn_1d", "qualname": "load_data", "kind": "function", "doc": "<p>Load the data from the directories and label it as 'gol' or 'no_gol'.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: Array of audio data.\n  np.ndarray: Array of labels ('gol' or 'no_gol').</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn_1d.build_model", "modulename": "src.training.cnn_1d", "qualname": "build_model", "kind": "function", "doc": "<p>Build and compile a 1D convolutional neural network model.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>input_shape (tuple):</strong>  The shape of the input data.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tf.keras.Model: The compiled CNN model.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_shape</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.cnn_1d.main", "modulename": "src.training.cnn_1d", "qualname": "main", "kind": "function", "doc": "<p>Main function to load data, build and train the model, and evaluate the results.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.gradient_boosting", "modulename": "src.training.gradient_boosting", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.gradient_boosting.main", "modulename": "src.training.gradient_boosting", "qualname": "main", "kind": "function", "doc": "<p>Runs the Gradient Boosting model for predicting goal success and team classification.</p>\n\n<p>This function loads the processed data from a CSV file, trains and evaluates\ntwo Gradient Boosting models:\n    1. A model to predict if a goal was scored.\n    2. A model to predict the team that scored the goal when Goal_Success is 1.</p>\n\n<p>The results of these models are saved, and the models are serialized using\njoblib for future use.</p>\n\n<h6 id=\"it-performs-the-following-steps\">It performs the following steps:</h6>\n\n<blockquote>\n  <ol>\n  <li>Loads and preprocesses data.</li>\n  <li>Trains a Gradient Boosting model to predict goal success.</li>\n  <li>Trains a Gradient Boosting model to predict the team when a goal is scored.</li>\n  <li>Saves the trained models to disk.</li>\n  </ol>\n</blockquote>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.lstm", "modulename": "src.training.lstm", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.lstm.SR", "modulename": "src.training.lstm", "qualname": "SR", "kind": "variable", "doc": "<p></p>\n", "default_value": "8000"}, {"fullname": "src.training.lstm.DURATION", "modulename": "src.training.lstm", "qualname": "DURATION", "kind": "variable", "doc": "<p></p>\n", "default_value": "20"}, {"fullname": "src.training.lstm.SAMPLES_PER_TRACK", "modulename": "src.training.lstm", "qualname": "SAMPLES_PER_TRACK", "kind": "variable", "doc": "<p></p>\n", "default_value": "160000"}, {"fullname": "src.training.lstm.load_audio", "modulename": "src.training.lstm", "qualname": "load_audio", "kind": "function", "doc": "<p>Loads an audio file and processes it to the desired length.</p>\n\n<p>The audio file is loaded with librosa, and if its length exceeds the\nspecified maximum length, it is truncated. If the audio is shorter than\nthe specified maximum length, it is zero-padded.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>file_path (str):</strong>  The file path to the audio file.</li>\n<li><strong>sr (int, optional):</strong>  The sample rate for loading the audio. Defaults to 8000.</li>\n<li><strong>maxlen (int, optional):</strong>  The maximum length of the audio file in samples. Defaults to 160000.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>np.ndarray: A numpy array of the processed audio.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">file_path</span>, </span><span class=\"param\"><span class=\"n\">sr</span><span class=\"o\">=</span><span class=\"mi\">8000</span>, </span><span class=\"param\"><span class=\"n\">maxlen</span><span class=\"o\">=</span><span class=\"mi\">160000</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.lstm.load_data", "modulename": "src.training.lstm", "qualname": "load_data", "kind": "function", "doc": "<p>Loads the goal and no-goal audio files and labels from the specified folders.</p>\n\n<p>The function loads all <code>.wav</code> files from two folders (goal and no-goal)\nand returns them as a numpy array of features (X) and corresponding labels (y).</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>gol_folder (str):</strong>  Path to the folder containing goal audio files.</li>\n<li><strong>no_gol_folder (str):</strong>  Path to the folder containing no-goal audio files.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple: A tuple containing two numpy arrays:\n      - X (np.ndarray): The array of audio samples.\n      - y (np.ndarray): The array of labels ('goal' or 'no_goal').</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">gol_folder</span>, </span><span class=\"param\"><span class=\"n\">no_gol_folder</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.lstm.build_model", "modulename": "src.training.lstm", "qualname": "build_model", "kind": "function", "doc": "<p>Builds and compiles an LSTM model for binary classification.</p>\n\n<p>This function defines a Sequential LSTM model with dropout layers for\nregularization and compiles it using the Adam optimizer and binary\ncross-entropy loss.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>input_shape (tuple):</strong>  The shape of the input data (samples, features).</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>model (tf.keras.Model): A compiled Keras LSTM model ready for training.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">input_shape</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.lstm.train_and_evaluate", "modulename": "src.training.lstm", "qualname": "train_and_evaluate", "kind": "function", "doc": "<p>Trains and evaluates the LSTM model.</p>\n\n<p>The function trains the model on the training set and evaluates it on\nboth the validation and test sets. It also logs the accuracy and\nclassification report, displays a confusion matrix, and plots the accuracy\ncurves over epochs.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>model (tf.keras.Model):</strong>  The LSTM model to train and evaluate.</li>\n<li><strong>x_train (np.ndarray):</strong>  The input training data.</li>\n<li><strong>y_train (np.ndarray):</strong>  The target training labels.</li>\n<li><strong>x_test (np.ndarray):</strong>  The input test data.</li>\n<li><strong>y_test (np.ndarray):</strong>  The target test labels.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple: A tuple containing:\n      - y_val_pred (np.ndarray): The predicted labels for the training set.\n      - y_test_pred (np.ndarray): The predicted labels for the test set.\n      - history (tf.keras.callbacks.History): The training history object.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">x_train</span>, </span><span class=\"param\"><span class=\"n\">y_train</span>, </span><span class=\"param\"><span class=\"n\">x_test</span>, </span><span class=\"param\"><span class=\"n\">y_test</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.lstm.main", "modulename": "src.training.lstm", "qualname": "main", "kind": "function", "doc": "<p>Main function to train and evaluate an LSTM model for audio classification.</p>\n\n<p>The function loads the audio data, prepares it, splits it into training and\ntest sets, builds the LSTM model, trains it, and evaluates its performance.\nThe results are then saved.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.model_comparator", "modulename": "src.training.model_comparator", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.model_comparator.load_metrics", "modulename": "src.training.model_comparator", "qualname": "load_metrics", "kind": "function", "doc": "<p>Loads model performance metrics from a CSV file into a pandas DataFrame.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>csv_path (str):</strong>  Path to the CSV file containing model metrics.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>pd.DataFrame: A DataFrame with models as index and their corresponding metrics as columns.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">csv_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.model_comparator.plot_metrics", "modulename": "src.training.model_comparator", "qualname": "plot_metrics", "kind": "function", "doc": "<p>Generates a bar plot comparing model performance metrics.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>df (pd.DataFrame):</strong>  DataFrame containing model metrics, with models as the index and metrics as columns.</li>\n<li><strong>figsize (tuple, optional):</strong>  The size of the plot. Defaults to (10, 6).</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>matplotlib.figure.Figure: The generated bar plot figure.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">figsize</span><span class=\"p\">:</span> <span class=\"nb\">tuple</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">6</span><span class=\"p\">)</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.model_comparator.main", "modulename": "src.training.model_comparator", "qualname": "main", "kind": "function", "doc": "<p>Main function to load model performance metrics and plot a comparison.</p>\n\n<p>Reads the model performance data from a CSV file, generates a bar plot comparing the metrics,\nand displays the plot.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.random_forest", "modulename": "src.training.random_forest", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.random_forest.VERBOSE", "modulename": "src.training.random_forest", "qualname": "VERBOSE", "kind": "variable", "doc": "<p></p>\n", "default_value": "True"}, {"fullname": "src.training.random_forest.train_and_evaluate_model", "modulename": "src.training.random_forest", "qualname": "train_and_evaluate_model", "kind": "function", "doc": "<p>Trains and evaluates a Random Forest classifier on the given dataset.</p>\n\n<p>Splits the data into training, validation, and test sets, trains a RandomForestClassifier,\nevaluates it on validation and test data, and logs accuracy scores and classification report.\nAlso generates and displays a confusion matrix for model performance.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>x (pd.DataFrame):</strong>  The input features (independent variables) for training.</li>\n<li><strong>y (pd.Series):</strong>  The target labels (dependent variable) for training.</li>\n<li><strong>title (str):</strong>  A string used in the log and plot titles to specify which model is being evaluated.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>model (RandomForestClassifier): The trained Random Forest model.\n  y_val_pred (np.ndarray): Predicted labels for the validation set.\n  y_test_pred (np.ndarray): Predicted labels for the test set.\n  y_val (np.ndarray): True labels for the validation set.\n  y_test (np.ndarray): True labels for the test set.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">y</span>, </span><span class=\"param\"><span class=\"n\">title</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.random_forest.main", "modulename": "src.training.random_forest", "qualname": "main", "kind": "function", "doc": "<p>Main function to train and evaluate two models: Goal Success and Team Prediction.</p>\n\n<p>The function loads the dataset, processes it, trains two Random Forest models:\none for predicting goal success and another for predicting the team when a goal is successful.\nAfter training, the models are saved to disk, and results are logged.</p>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>None</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities", "modulename": "src.utilities", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.utilities.VERBOSE", "modulename": "src.utilities", "qualname": "VERBOSE", "kind": "variable", "doc": "<p></p>\n", "default_value": "True"}, {"fullname": "src.utilities.log", "modulename": "src.utilities", "qualname": "log", "kind": "function", "doc": "<p>Logs a message to the console if VERBOSE is set to True.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>message (str):</strong>  The message to log.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">message</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.convert_column", "modulename": "src.utilities", "qualname": "convert_column", "kind": "function", "doc": "<p>Converts columns with object types that represent lists of floats into their mean values.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>col (pandas.Series):</strong>  The column to convert.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>pandas.Series: The converted column.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">col</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.parse_np_float_list", "modulename": "src.utilities", "qualname": "parse_np_float_list", "kind": "function", "doc": "<p>Parses a string representing a list of np.float32 elements into a list of floats.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>s (str):</strong>  The string to parse.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>list: A list of float values.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">s</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.encode_team", "modulename": "src.utilities", "qualname": "encode_team", "kind": "function", "doc": "<p>Encodes team names into integer values: 1 for \"Real Madrid\", 0 for \"Visitor\", -1 for others.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>team (str):</strong>  The team name to encode.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>int: The encoded integer value of the team.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">team</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.save_results", "modulename": "src.utilities", "qualname": "save_results", "kind": "function", "doc": "<p>Saves evaluation metrics of a model to a CSV file.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>model_name (str):</strong>  The name of the model being evaluated.</li>\n<li><strong>y_val (array):</strong>  True labels for the validation set.</li>\n<li><strong>y_val_pred (array):</strong>  Predicted labels for the validation set.</li>\n<li><strong>y_test (array):</strong>  True labels for the test set.</li>\n<li><strong>y_test_pred (array):</strong>  Predicted labels for the test set.</li>\n<li><strong>csv_path (str):</strong>  The path to the CSV file where results should be saved.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">model_name</span>,</span><span class=\"param\">\t<span class=\"n\">y_val</span>,</span><span class=\"param\">\t<span class=\"n\">y_val_pred</span>,</span><span class=\"param\">\t<span class=\"n\">y_test</span>,</span><span class=\"param\">\t<span class=\"n\">y_test_pred</span>,</span><span class=\"param\">\t<span class=\"n\">csv_path</span><span class=\"o\">=</span><span class=\"s1\">&#39;D:</span><span class=\"se\">\\\\</span><span class=\"s1\">unican-listentothestadium</span><span class=\"se\">\\\\</span><span class=\"s1\">Data</span><span class=\"se\">\\\\</span><span class=\"s1\">Processed</span><span class=\"se\">\\\\</span><span class=\"s1\">models_results.csv&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.load_audio_data", "modulename": "src.utilities", "qualname": "load_audio_data", "kind": "function", "doc": "<p>Loads an audio file, converts it to a numpy array of samples, and returns it along with metadata.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>audio_path (str):</strong>  The path to the audio file.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple: A tuple containing the audio object, duration, sample rate, and the audio samples as a numpy array.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">audio_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.downsample_data", "modulename": "src.utilities", "qualname": "downsample_data", "kind": "function", "doc": "<p>Downsamples the audio samples and adjusts the time axis accordingly.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>samples (np.array):</strong>  The audio samples to downsample.</li>\n<li><strong>duration (float):</strong>  The duration of the audio in seconds.</li>\n<li><strong>factor (int):</strong>  The downsampling factor.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>tuple: The downsampled time axis and the downsampled audio samples.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">samples</span>, </span><span class=\"param\"><span class=\"n\">duration</span>, </span><span class=\"param\"><span class=\"n\">factor</span><span class=\"o\">=</span><span class=\"mi\">10</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.plot_event_intervals", "modulename": "src.utilities", "qualname": "plot_event_intervals", "kind": "function", "doc": "<p>Plots event intervals on a given axis.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>ax (matplotlib.axes.Axes):</strong>  The axis to plot on.</li>\n<li><strong>intervals (dict):</strong>  A dictionary of event intervals for each team.</li>\n<li><strong>colors (list):</strong>  A list of colors to use for different teams.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">ax</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">colors</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.plot_audio_with_events", "modulename": "src.utilities", "qualname": "plot_audio_with_events", "kind": "function", "doc": "<p>Plots the audio waveform with event intervals.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>audio_path (str):</strong>  The path to the audio file.</li>\n<li><strong>intervals (dict or list):</strong>  The event intervals to plot.</li>\n<li><strong>output_path (str):</strong>  The path to save the plot.</li>\n<li><strong>event_type (str):</strong>  The type of event being plotted (e.g., \"Goals\").</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">audio_path</span>, </span><span class=\"param\"><span class=\"n\">intervals</span>, </span><span class=\"param\"><span class=\"n\">output_path</span>, </span><span class=\"param\"><span class=\"n\">event_type</span><span class=\"o\">=</span><span class=\"s1\">&#39;Goals&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.ensure_directories_exist", "modulename": "src.utilities", "qualname": "ensure_directories_exist", "kind": "function", "doc": "<p>Ensures that all specified directories exist, creating them if necessary.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>directory_paths (list):</strong>  A list of directory paths to check/create.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">directory_paths</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.plot_audio_segments", "modulename": "src.utilities", "qualname": "plot_audio_segments", "kind": "function", "doc": "<p>Plots audio segments corresponding to specific event intervals and saves them as images.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>audio_path (str):</strong>  The path to the audio file.</li>\n<li><strong>intervals (dict or list):</strong>  The event intervals to plot.</li>\n<li><strong>event_type (str):</strong>  The type of event (e.g., \"Goals\").</li>\n<li><strong>output_folder (str):</strong>  The folder to save the output plots.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audio_path</span>,</span><span class=\"param\">\t<span class=\"n\">intervals</span>,</span><span class=\"param\">\t<span class=\"n\">event_type</span>,</span><span class=\"param\">\t<span class=\"n\">output_folder</span><span class=\"o\">=</span><span class=\"s1\">&#39;extract_audio_segments&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.plot_frequency_db_per_event", "modulename": "src.utilities", "qualname": "plot_frequency_db_per_event", "kind": "function", "doc": "<p>Plots the frequency spectrum of audio segments corresponding to event intervals and saves them.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>audio_path (str):</strong>  The path to the audio file.</li>\n<li><strong>intervals (dict or list):</strong>  The event intervals to plot.</li>\n<li><strong>event_type (str):</strong>  The type of event (e.g., \"Goals\").</li>\n<li><strong>output_folder (str):</strong>  The folder to save the output plots.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audio_path</span>,</span><span class=\"param\">\t<span class=\"n\">intervals</span>,</span><span class=\"param\">\t<span class=\"n\">event_type</span>,</span><span class=\"param\">\t<span class=\"n\">output_folder</span><span class=\"o\">=</span><span class=\"s1\">&#39;frequency_db_output&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.train_and_evaluate_model", "modulename": "src.utilities", "qualname": "train_and_evaluate_model", "kind": "function", "doc": "<p>Train and evaluate a machine learning model using AdaBoost or Gradient Boosting.</p>\n\n<p>This function splits the input dataset into training, validation, and test sets. It then trains\na model (either AdaBoost or Gradient Boosting) on the training data, and evaluates the model's\nperformance on both the validation and test sets. It logs the accuracy, prints a classification report,\nand displays a confusion matrix heatmap for visual analysis.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>model (str):</strong>  The name of the model to use. It can be either 'ada_boost' or 'gradient_boosting'.</li>\n<li><strong>x (array-like):</strong>  Features for training and evaluation.</li>\n<li><strong>y (array-like):</strong>  Target labels for training and evaluation.</li>\n<li><strong>title (str):</strong>  A title used for logging and the confusion matrix. Typically indicates the context (e.g., \"Team\").</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>model: The trained model.\n  y_val_pred (array-like): Predicted labels for the validation set.\n  y_test_pred (array-like): Predicted labels for the test set.\n  y_val (array-like): Actual labels for the validation set.\n  y_test (array-like): Actual labels for the test set.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">x</span>, </span><span class=\"param\"><span class=\"n\">y</span>, </span><span class=\"param\"><span class=\"n\">title</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.utilities.train_and_evaluate", "modulename": "src.utilities", "qualname": "train_and_evaluate", "kind": "function", "doc": "<p>Train and evaluate a deep learning model with callbacks for early stopping and learning rate adjustment.</p>\n\n<p>This function trains a deep learning model using the provided training and test data. It applies\ncallbacks to adjust the learning rate and stop training early if the validation loss does not improve.\nThe function also generates a plot of training and validation accuracy over the epochs, logs the accuracy,\nprints a classification report, and displays a confusion matrix.</p>\n\n<h6 id=\"arguments\">Arguments:</h6>\n\n<ul>\n<li><strong>model (tensorflow.keras.Model):</strong>  The deep learning model to train.</li>\n<li><strong>x_train (array-like):</strong>  Features for training.</li>\n<li><strong>y_train (array-like):</strong>  Target labels for training.</li>\n<li><strong>x_test (array-like):</strong>  Features for testing.</li>\n<li><strong>y_test (array-like):</strong>  Target labels for testing.</li>\n<li><strong>class_weights (dict):</strong>  A dictionary containing class weights for handling class imbalance.</li>\n<li><strong>model_path (str):</strong>  The path where the model should be saved if it achieves the best validation performance.</li>\n</ul>\n\n<h6 id=\"returns\">Returns:</h6>\n\n<blockquote>\n  <p>y_val_pred (array-like): Predicted labels for the training set.\n  y_test_pred (array-like): Predicted labels for the test set.\n  history (tensorflow.keras.callbacks.History): History object containing training metrics.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">x_train</span>, </span><span class=\"param\"><span class=\"n\">y_train</span>, </span><span class=\"param\"><span class=\"n\">x_test</span>, </span><span class=\"param\"><span class=\"n\">y_test</span>, </span><span class=\"param\"><span class=\"n\">class_weights</span>, </span><span class=\"param\"><span class=\"n\">model_path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();